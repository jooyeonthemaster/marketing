"""
í¬ë¡¤ë§ëœ ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥ ìœ í‹¸ë¦¬í‹°
Excel, CSV, JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì €ì¥ ê¸°ëŠ¥
"""

import pandas as pd
import json
import os
from datetime import datetime
from typing import Dict, List, Optional
import logging
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config.settings import OUTPUT_SETTINGS


class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.setup_logging()
        self.ensure_output_directory()
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        self.logger = logging.getLogger(__name__)
    
    def ensure_output_directory(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        output_dir = OUTPUT_SETTINGS['output_directory']
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            self.logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
    
    def process_crawling_results(self, results: Dict[str, List[Dict]]) -> pd.DataFrame:
        """í¬ë¡¤ë§ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        try:
            all_data = []
            
            for keyword, places in results.items():
                for place in places:
                    # ê¸°ë³¸ ì •ë³´ì— í‚¤ì›Œë“œ ì¶”ê°€
                    place_data = place.copy()
                    place_data['search_keyword'] = keyword
                    place_data['crawled_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    # ë°ì´í„° ì •ì œ
                    place_data = self.clean_place_data(place_data)
                    all_data.append(place_data)
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(all_data)
            
            if not df.empty:
                # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
                column_order = [
                    'search_keyword', 'rank', 'name', 'address', 'category',
                    'rating', 'review_count', 'phone', 'url', 'crawled_at'
                ]
                
                # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
                available_columns = [col for col in column_order if col in df.columns]
                df = df[available_columns]
                
                # ì •ë ¬
                df = df.sort_values(['search_keyword', 'rank']).reset_index(drop=True)
            
            self.logger.info(f"ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(df)} ê±´")
            return df
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def clean_place_data(self, place_data: Dict) -> Dict:
        """ì¥ì†Œ ë°ì´í„° ì •ì œ"""
        try:
            # í…ìŠ¤íŠ¸ ì •ì œ
            for key, value in place_data.items():
                if isinstance(value, str):
                    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
                    value = value.strip()
                    # ê°œí–‰ë¬¸ì ì œê±°
                    value = value.replace('\n', ' ').replace('\r', ' ')
                    # ì—°ì†ëœ ê³µë°± ì œê±°
                    value = ' '.join(value.split())
                    place_data[key] = value
            
            # í‰ì  ìˆ«ì ì¶”ì¶œ
            if place_data.get('rating'):
                rating_text = place_data['rating']
                # ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: "4.5ì " -> "4.5")
                import re
                rating_match = re.search(r'(\d+\.?\d*)', rating_text)
                if rating_match:
                    place_data['rating'] = rating_match.group(1)
            
            # ë¦¬ë·° ìˆ˜ ìˆ«ì ì¶”ì¶œ
            if place_data.get('review_count'):
                review_text = place_data['review_count']
                # ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: "ë¦¬ë·° 125ê°œ" -> "125")
                import re
                review_match = re.search(r'(\d+)', review_text.replace(',', ''))
                if review_match:
                    place_data['review_count'] = review_match.group(1)
            
            return place_data
            
        except Exception as e:
            self.logger.warning(f"ë°ì´í„° ì •ì œ ì‹¤íŒ¨: {e}")
            return place_data
    
    def save_to_excel(self, df: pd.DataFrame, filename: Optional[str] = None) -> str:
        """Excel íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if filename is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"naver_places_ranking_{timestamp}.xlsx"
            
            output_path = os.path.join(OUTPUT_SETTINGS['output_directory'], filename)
            
            # Excel ì €ì¥ (ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ êµ¬ì„±)
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ì „ì²´ ë°ì´í„°
                df.to_excel(writer, sheet_name='ì „ì²´_ë°ì´í„°', index=False)
                
                # í‚¤ì›Œë“œë³„ ì‹œíŠ¸ ìƒì„±
                if 'search_keyword' in df.columns:
                    for keyword in df['search_keyword'].unique():
                        keyword_df = df[df['search_keyword'] == keyword]
                        sheet_name = keyword[:30]  # ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ
                        keyword_df.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # ìš”ì•½ í†µê³„
                if not df.empty:
                    summary_data = self.create_summary_stats(df)
                    summary_df = pd.DataFrame(summary_data)
                    summary_df.to_excel(writer, sheet_name='ìš”ì•½_í†µê³„', index=False)
            
            self.logger.info(f"Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"Excel ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def save_to_csv(self, df: pd.DataFrame, filename: Optional[str] = None) -> str:
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if filename is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"naver_places_ranking_{timestamp}.csv"
            
            output_path = os.path.join(OUTPUT_SETTINGS['output_directory'], filename)
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            
            self.logger.info(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def save_to_json(self, results: Dict[str, List[Dict]], filename: Optional[str] = None) -> str:
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if filename is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"naver_places_ranking_{timestamp}.json"
            
            output_path = os.path.join(OUTPUT_SETTINGS['output_directory'], filename)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            output_data = {
                'metadata': {
                    'crawled_at': datetime.now().isoformat(),
                    'total_keywords': len(results),
                    'total_places': sum(len(places) for places in results.values())
                },
                'data': results
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def create_summary_stats(self, df: pd.DataFrame) -> List[Dict]:
        """ìš”ì•½ í†µê³„ ìƒì„±"""
        try:
            summary_data = []
            
            if 'search_keyword' in df.columns:
                for keyword in df['search_keyword'].unique():
                    keyword_df = df[df['search_keyword'] == keyword]
                    
                    stats = {
                        'ê²€ìƒ‰_í‚¤ì›Œë“œ': keyword,
                        'ì´_ì¥ì†Œ_ìˆ˜': len(keyword_df),
                        'í‰ê· _í‰ì ': '',
                        'í‰ê· _ë¦¬ë·°_ìˆ˜': '',
                        'ì¹´í…Œê³ ë¦¬_ìˆ˜': ''
                    }
                    
                    # í‰ì  í†µê³„
                    if 'rating' in keyword_df.columns:
                        try:
                            numeric_ratings = pd.to_numeric(keyword_df['rating'], errors='coerce')
                            if not numeric_ratings.isna().all():
                                stats['í‰ê· _í‰ì '] = f"{numeric_ratings.mean():.2f}"
                        except:
                            pass
                    
                    # ë¦¬ë·° ìˆ˜ í†µê³„
                    if 'review_count' in keyword_df.columns:
                        try:
                            numeric_reviews = pd.to_numeric(keyword_df['review_count'], errors='coerce')
                            if not numeric_reviews.isna().all():
                                stats['í‰ê· _ë¦¬ë·°_ìˆ˜'] = f"{numeric_reviews.mean():.0f}"
                        except:
                            pass
                    
                    # ì¹´í…Œê³ ë¦¬ í†µê³„
                    if 'category' in keyword_df.columns:
                        unique_categories = keyword_df['category'].nunique()
                        stats['ì¹´í…Œê³ ë¦¬_ìˆ˜'] = unique_categories
                    
                    summary_data.append(stats)
            
            return summary_data
            
        except Exception as e:
            self.logger.error(f"ìš”ì•½ í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def save_all_formats(self, results: Dict[str, List[Dict]]) -> Dict[str, str]:
        """ëª¨ë“  í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        saved_files = {}
        
        try:
            # DataFrame ìƒì„±
            df = self.process_crawling_results(results)
            
            if not df.empty:
                # Excel ì €ì¥
                excel_path = self.save_to_excel(df)
                if excel_path:
                    saved_files['excel'] = excel_path
                
                # CSV ì €ì¥
                csv_path = self.save_to_csv(df)
                if csv_path:
                    saved_files['csv'] = csv_path
            
            # JSON ì €ì¥ (ì›ë³¸ ë°ì´í„°)
            json_path = self.save_to_json(results)
            if json_path:
                saved_files['json'] = json_path
            
            self.logger.info(f"ëª¨ë“  í˜•ì‹ ì €ì¥ ì™„ë£Œ: {list(saved_files.keys())}")
            return saved_files
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return saved_files
    
    def print_summary(self, results: Dict[str, List[Dict]]) -> None:
        """í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        try:
            print("\n" + "="*60)
            print("ë„¤ì´ë²„ ì§€ë„ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½")
            print("="*60)
            
            total_places = 0
            for keyword, places in results.items():
                print(f"\nğŸ” í‚¤ì›Œë“œ: {keyword}")
                print(f"   â””â”€ ìˆ˜ì§‘ëœ ì¥ì†Œ: {len(places)}ê°œ")
                total_places += len(places)
                
                if places:
                    # ìƒìœ„ 3ê°œ ì¥ì†Œ ë¯¸ë¦¬ë³´ê¸°
                    print("   â””â”€ ìƒìœ„ ì¥ì†Œ:")
                    for i, place in enumerate(places[:3], 1):
                        name = place.get('name', 'ì´ë¦„ ì—†ìŒ')
                        rating = place.get('rating', 'N/A')
                        print(f"      {i}. {name} (í‰ì : {rating})")
            
            print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
            print(f"   â€¢ ì´ í‚¤ì›Œë“œ ìˆ˜: {len(results)}ê°œ")
            print(f"   â€¢ ì´ ìˆ˜ì§‘ ì¥ì†Œ: {total_places}ê°œ")
            print(f"   â€¢ í‰ê·  ì¥ì†Œ/í‚¤ì›Œë“œ: {total_places/len(results):.1f}ê°œ")
            
            print("\n" + "="*60)
            
        except Exception as e:
            self.logger.error(f"ìš”ì•½ ì¶œë ¥ ì‹¤íŒ¨: {e}") 